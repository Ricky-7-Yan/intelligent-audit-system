# 📥 HuggingFace模型下载说明

<div align="center">

![Model](https://img.shields.io/badge/Model-SentenceTransformers-blue.svg)
![Size](https://img.shields.io/badge/Size-420MB-green.svg)
![Languages](https://img.shields.io/badge/Languages-100+-purple.svg)

**模型下载指南 | 支持100+种语言的多语言嵌入模型**

</div>

---

## 📋 目录

- [问题描述](#-问题描述)
- [下载方法](#-下载方法)
- [自动检测](#-自动检测)
- [常见问题](#-常见问题)

---

## ❓ 问题描述

项目需要下载HuggingFace模型，但在中国大陆地区访问HuggingFace较慢或无法访问。

✅ **系统已优化**: 优先使用本地模型，如果本地不存在才尝试下载

---

## 📥 下载方法

### 🌟 方案1：使用镜像站（强烈推荐）⭐

项目已自动配置使用HF-Mirror镜像站。

#### 💻 Windows用户

```powershell
# 设置镜像环境变量
$env:HF_ENDPOINT="https://hf-mirror.com"

# 启动系统（会自动下载）
python web/main.py
```

#### 🐧 Linux/Mac用户

```bash
# 设置镜像环境变量
export HF_ENDPOINT=https://hf-mirror.com

# 启动系统（会自动下载）
python web/main.py
```

### 📦 方案2：手动下载模型

如果需要手动下载模型到本地：

```bash
# 设置镜像环境变量
export HF_ENDPOINT=https://hf-mirror.com

# 下载模型
python -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
    local_dir='./models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
)
print('✅ 模型下载完成！')
"
```

📁 **下载完成后，模型将保存在**:
```
intelligent-audit-system/
  └── models/
      └── sentence-transformers/
          └── paraphrase-multilingual-MiniLM-L12-v2/
              ├── config.json              # 模型配置
              ├── modules.json             # 模块配置
              ├── pytorch_model.bin        # PyTorch模型权重 ⚙️
              ├── tokenizer_config.json    # 分词器配置
              ├── vocab.txt                # 词汇表
              └── sentence_bert_config.json # Sentence-BERT配置
```

### 🔐 方案3：使用VPN

如果您有VPN，可以：
1. 🔌 连接VPN
2. ▶️ 正常运行系统，模型会自动下载

---

## 🔍 系统自动检测

系统会按以下顺序检测模型：

| 优先级 | 检测项 | 说明 |
|--------|--------|------|
| 1️⃣ | 💾 **本地模型** | 检查路径: `./models/sentence-transformers/...` |
| 2️⃣ | 🌐 **镜像站下载** | 从 `https://hf-mirror.com` 下载 |
| 3️⃣ | 🌍 **官方站下载** | 从官方站下载（可能需要VPN） |
| 4️⃣ | ⚠️ **简化模式** | 如果所有下载都失败，系统运行在简化模式下 |

### ✅ 验证模型是否下载成功

启动系统后，查看日志输出：

**✅ 成功使用本地模型**:
```
INFO:rag.agentic_rag:使用本地模型: /path/to/models/sentence-transformers/...
```

**⏳ 正在下载模型**:
```
INFO:rag.agentic_rag:尝试从镜像站下载模型...
```

---

## 📊 模型文件列表

需要下载的核心文件：

| 文件名 | 大小 | 说明 |
|--------|------|------|
| `config.json` | ~1KB | 模型配置 |
| `modules.json` | ~500B | 模块配置 |
| `pytorch_model.bin` | ~420MB | PyTorch模型权重 |
| `tokenizer_config.json` | ~2KB | 分词器配置 |
| `vocab.txt` | ~200KB | 词汇表 |
| `sentence_bert_config.json` | ~1KB | Sentence-BERT配置 |

📦 **总大小**: 约 420MB

---

## 💻 代码中的配置

在 `rag/agentic_rag.py` 中，系统会自动检测本地模型：

```python
# 检查本地模型路径
local_model_path = PATHS['models'] / 'sentence-transformers' / 'paraphrase-multilingual-MiniLM-L12-v2'

if os.path.exists(local_model_path):
    logger.info(f"使用本地模型: {local_model_path}")
    self.embedding_model = HuggingFaceEmbeddings(
        model_name=str(local_model_path),
        model_kwargs={'device': 'cpu'}
    )
else:
    # 使用镜像站下载
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    logger.info("尝试从镜像站下载模型...")
    self.embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'}
    )
```

---

## ❓ 常见问题

### ❓ 下载速度很慢怎么办？

**A**: 使用镜像站 `https://hf-mirror.com`，速度更快 ⚡

### ❓ 下载失败怎么办？

**A**: 系统会自动降级到简化模式，不影响基本功能（智能对话等） ✅

### ❓ 如何检查模型是否已下载？

**A**: 检查 `models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/` 目录是否存在 📁

### ❓ 可以更换其他模型吗？

**A**: 可以，修改 `rag/agentic_rag.py` 中的模型名称即可

**🌟 推荐的多语言模型**:
- `paraphrase-multilingual-MiniLM-L12-v2` (当前使用) 📌
- `paraphrase-multilingual-mpnet-base-v2`
- `distiluse-base-multilingual-cased`

---

## 🌐 中国镜像站列表

| 镜像站 | 地址 | 状态 |
|--------|------|------|
| HF-Mirror | https://hf-mirror.com | ✅ 推荐 |
| OpenI | https://openi.org.cn/hf-models | ✅ 可用 |
| 魔搭社区 | https://modelscope.cn | ✅ 可用 |

---

## 💾 离线使用

如果想完全离线使用：

1. 📥 在有网络的机器上下载模型
2. 📦 将 `models/` 目录复制到目标机器
3. ▶️ 运行系统，会自动使用本地模型

---

## ⚡ 性能说明

| 指标 | 数值 |
|------|------|
| 📦 **模型大小** | ~420MB |
| ⏱️ **加载时间** | 首次约30秒，后续约10秒 |
| 💾 **内存占用** | ~500MB |
| 🌐 **支持语言** | 100+种语言（包括中文） |

---

## 📝 更新日志

| 日期         | 更新内容 |
|------------|---------|
| 2025-10-28 | ✨ 优化本地模型检测逻辑 |
| 2025-10-28 | 🌐 添加镜像站自动配置 |
| 2025-10-28 | ⚠️ 添加失败降级机制 |

---

<div align="center">

**📚 相关文档**

[返回首页](README.md) • [配置指南](PyCharm_Setup_Guide.md) • [项目总结](Project_Summary.md)

Made with ❤️ by Intelligent Audit Team

</div>
